{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Search and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybliometrics\n",
    "from pybliometrics.scopus.utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybliometrics.scopus import ScopusSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a Scopus Query\n",
    "\n",
    "You can search for documents using author name (as we did in notebook \"02\") or by a variety of other fields (affiliation, publication name, date range, etc.).\n",
    "\n",
    "However, often, researchers will want to search for a term or set of terms across multiple fields. Some example queries are below:\n",
    "\n",
    "* `ABS(dopamine)` returns documents where \"dopamine\" is in the document abstract.\n",
    "* `AUTHKEY(stroke)` returns documents where \"stroke\" is an author keyword.\n",
    "* `CHEMNAME(oxidopamine)` returns documents with \"oxidopamine\" in the chemical name field.\n",
    "* `FUND-ACR(NASA)` returns documents with NASA mentioned as the sponsor acronym in the acknowledgements section of the article. \n",
    "* `LANGUAGE(french)` returns documents originally written in French.\n",
    "* `OPENACCESS(1)` returns Open Access content indexed in Scopus.\n",
    "* `OPENACCESS(0)` returns subscription-based content indexed in Scopus.\n",
    "* `PUBYEAR > 1994` returns documents with a publication year after 1994.\n",
    "* `PUBYEAR < 1994` returns documents with a publication year before 1994.\n",
    "* `PUBYEAR = 1994` returns documents with a publication year of 1994. \n",
    "* To find documents where your search terms occur in the same reference, use: `REF(darwin 1859)`\n",
    "* `SRCTYPE(j)` returns documents from journal sources.\n",
    "* `TITLE(\"neuropsychological evidence\")` returns documents with the phrase \"neuropsychological evidence\" in their title.\n",
    "\n",
    "If you want to search across multiple fields, you can also use the following combined fields:\n",
    "* `ALL(\"heart attack\")` returns documents with \"heart attack\" in any field\n",
    "* `KEY(oscillator)` returns documents where \"oscillator\" is a keyword.\n",
    "    * searches the AUTHKEY, INDEXTERMS, TRADENAME, and CHEMNAME fields\n",
    "* `TITLE-ABS-KEY(\"heart attack\")` returns documents with \"heart attack\" in their abstracts, article titles, or keyword fields.\n",
    "* `TITLE-ABS-KEY-AUTH(heart attack)` returns documents with \"heart attack\" in their abstracts, article titles, keywords, or author name fields.\n",
    "\n",
    "For more on search queries within Scopus review its [Search Tips page](https://dev.elsevier.com/sc_search_tips.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple search \n",
    "# only takes seconds on Scopus web platform, but takes 30-60 seconds for every 1000 records or so\n",
    "query = \"TITLE-ABS-KEY(bibliometrics)\"\n",
    "\n",
    "# to speed this up, we recommend for your first search, \n",
    "## adding the parameter \"download=False\"\n",
    "## once you are sure you are getting the type and number of results \n",
    "## you want you can remove this parameter\n",
    "\n",
    "# results\n",
    "s = ScopusSearch(query, download=False)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "The above search yields tens of thousands of records. Unfortunately, the Scopus API is slow to retrieve this number of records. Therefore, as you are testing your code it makes sense to retrieve a smaller subset of results. You can always go back and request a larger number of results once you know your code is working well.\n",
    "\n",
    "Below, we will write some code that narrows the search results to only those publications written since 2023 and that also use the term \"scopus\" in one of its key fields. We will then place the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "We can then use the **.get_eids()** method to retrieve the eids for each document that matches the search query above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Abstracts\n",
    "\n",
    "If we want to get more detailed information about the documents we identified above, we can use the pybliometric's **AuthorRetrieval** class to retrieve this info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybliometrics.scopus import AbstractRetrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe of document data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and using a function to compile document data\n",
    "\n",
    "We can create and call a function to place data from multiple documents into a dataframe, while also specifying the columns we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../code')\n",
    "import scopusapi_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dictionary below we specify the data fields we want to retrieve for each document. A Python dictionary contains a list of key/value pairs. Below, the format is:\n",
    "\n",
    "    [KEY = name we want to give to resulting dataframe] : [VALUE: name of field as set by Scopus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldict = {\"doc_eid\": \"eid\", \"doi\": \"doi\", \"authors\": \"authors\",\n",
    "           \"title\": \"title\", \n",
    "           \"pub_title\": \"publicationName\", \"volume\": \"volume\",\n",
    "           \"date\": \"coverDate\", \n",
    "           \"abstract\": \"abstract\", \"description\": \"description\",\n",
    "           \"citedby_count\": \"citedby_count\", \n",
    "           \"authkeywords\": \"authkeywords\", \n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df = pd.DataFrame()\n",
    "\n",
    "for eid in eids:\n",
    "    abstract_dict = scopusapi_functions.get_scopus_abstractinfo(eid, coldict)\n",
    "    new_df = pd.DataFrame([abstract_dict])\n",
    "    ab_df = pd.concat([ab_df, new_df], ignore_index=True)\n",
    "\n",
    "print(ab_df.shape)\n",
    "ab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Conduct your own search / query of the Scopus dataset using the ScopusSearch function. Save a list of eids for each of these documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Using the list of eids created above, use the AbstractRetrieval function to retrieve detailed document info about each of these documents and place this resulting information into a dataframe and export as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
